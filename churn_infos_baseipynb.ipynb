{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuriborg/dsmkt/blob/main/churn_infos_baseipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Engineering Functions"
      ],
      "metadata": {
        "id": "Y75ZiY_lQtOR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1LGAPHRuQktI"
      },
      "outputs": [],
      "source": [
        "def remove_accents(input_str):\n",
        "    nfkd_form = unicodedata.normalize('NFKD', input_str)\n",
        "    only_ascii = nfkd_form.encode('ASCII', 'ignore')\n",
        "    return only_ascii.decode('utf-8')\n",
        "\n",
        "def read_sheet(\n",
        "    sheet_ID,\n",
        "    sheet_range_name\n",
        "):\n",
        "    # Call the Sheets API\n",
        "    fromSheet = service.spreadsheets()\n",
        "    result_sheet = fromSheet.values().get(spreadsheetId=sheet_ID,\n",
        "                                range=sheet_range_name).execute()\n",
        "    values_sheet = result_sheet.get('values', [])\n",
        "    data = pd.DataFrame(values_sheet[1:], columns=values_sheet[0])\n",
        "    return data\n",
        "\n",
        "def apply_standardization(\n",
        "    data\n",
        "):\n",
        "    #Apply functions to remove accents, parentheses with empty spaces\n",
        "    #replaces upper case letters withll case letters,\n",
        "    #and replaces empty spaces with underscores\n",
        "    data.columns = list(map(remove_accents, data.columns))\n",
        "    data.columns = list(map(lambda x: x.lower().replace(' ', '_').replace('(', '').replace(')', ''),\n",
        "                             data.columns))\n",
        "    return data\n",
        "\n",
        "def findcol(val):\n",
        "    return list(filter(lambda x: val.lower() in x.lower(), df.columns))\n",
        "\n",
        "\n",
        "def get_cat_num_vars(df):\n",
        "    # separating categorical and numerical\n",
        "    cat_cols = df.select_dtypes(exclude='number').columns\n",
        "    num_cols = df.select_dtypes(include='number').columns\n",
        "    return cat_cols, num_cols\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Data Extraction\n"
      ],
      "metadata": {
        "id": "fK-tNRZKQzlu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_accents(input_str):\n",
        "    nfkd_form = unicodedata.normalize('NFKD', input_str)\n",
        "    only_ascii = nfkd_form.encode('ASCII', 'ignore')\n",
        "    return only_ascii.decode('utf-8')\n",
        "\n",
        "def read_sheet(\n",
        "    sheet_ID,\n",
        "    sheet_range_name\n",
        "):\n",
        "    # Call the Sheets API\n",
        "    fromSheet = service.spreadsheets()\n",
        "    result_sheet = fromSheet.values().get(spreadsheetId=sheet_ID,\n",
        "                                range=sheet_range_name).execute()\n",
        "    values_sheet = result_sheet.get('values', [])\n",
        "    data = pd.DataFrame(values_sheet[1:], columns=values_sheet[0])\n",
        "    return data\n",
        "\n",
        "def apply_standardization(\n",
        "    data\n",
        "):\n",
        "    #Apply functions to remove accents, parentheses with empty spaces\n",
        "    #replaces upper case letters withll case letters,\n",
        "    #and replaces empty spaces with underscores\n",
        "    data.columns = list(map(remove_accents, data.columns))\n",
        "    data.columns = list(map(lambda x: x.lower().replace(' ', '_').replace('(', '').replace(')', ''),\n",
        "                             data.columns))\n",
        "    return data\n",
        "\n",
        "def findcol(val):\n",
        "    return list(filter(lambda x: val.lower() in x.lower(), df.columns))\n",
        "\n",
        "\n",
        "def get_cat_num_vars(df):\n",
        "    # separating categorical and numerical\n",
        "    cat_cols = df.select_dtypes(exclude='number').columns\n",
        "    num_cols = df.select_dtypes(include='number').columns\n",
        "    return cat_cols, num_cols\n"
      ],
      "metadata": {
        "id": "_QIJ0LvwQz8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Balanceamento"
      ],
      "metadata": {
        "id": "pc2AMONLQ44I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_balance(df):\n",
        "    return pd.DataFrame({\n",
        "            'classes': (df['e_desligado'].value_counts()).index,\n",
        "            'frequÃªncia': (df['e_desligado'].value_counts()).values,\n",
        "            '%': (df['e_desligado'].value_counts()*100/len(df)).values\n",
        "        })\n",
        "get_balance(df)"
      ],
      "metadata": {
        "id": "RUcbfuAwQ5JN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import unicodedata\n",
        "\n",
        "def remove_accents(input_str):\n",
        "    nfkd_form = unicodedata.normalize('NFKD', input_str)\n",
        "    only_ascii = nfkd_form.encode('ASCII', 'ignore')\n",
        "    return only_ascii.decode('utf-8')\n",
        "\n",
        "\n",
        "def filter_alphanum_str(x):\n",
        "    return remove_accents(re.sub(r'\\W+', '', x))\n",
        "\n",
        "def get_features_labels_subset(df,\n",
        "                               features,\n",
        "                               p = 0.8,\n",
        "                               target_label = 'e_desligado',\n",
        "                               adjust_columns = False\n",
        "                              ):\n",
        "    t = df.copy()\n",
        "\n",
        "    if adjust_columns:\n",
        "        t.columns = list(map(\n",
        "            lambda x: x.replace('.0', '').replace('>', 'maior').replace('<','menor').replace('[','').replace(']','').replace('-','').replace(',','_').replace('+','mais'),\n",
        "                                   t.columns))\n",
        "        t.columns = list(map(filter_alphanum_str, t.columns))\n",
        "\n",
        "        features = list(map(\n",
        "            lambda x: x.replace('.0', '').replace('>', 'maior').replace('<','menor').replace('[','').replace(']','').replace('-','').replace(',','_').replace('+','mais'),\n",
        "                                   features))\n",
        "        features = list(map(filter_alphanum_str, features))\n",
        "\n",
        "\n",
        "    N = len(t)\n",
        "    N_train = round(N * p)\n",
        "    N_test = N - N_train\n",
        "\n",
        "    X_train, X_test = t[features].loc[:N_train], t[features].loc[N_train:]\n",
        "    y_train, y_test = t[target_label].loc[:N_train].values, t[target_label].loc[N_train:].values\n",
        "\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "X_train, y_train, X_test, y_test = get_features_labels_subset(df,\n",
        "                               features,\n",
        "                               p = 0.8,\n",
        "                               target_label = 'e_desligado',\n",
        "                               adjust_columns = True\n",
        "                              )\n",
        "X_train.shape, X_test.shape, X_train.shape[0]+X_test.shape[0], df.shape"
      ],
      "metadata": {
        "id": "48uZArjfQ_qZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = X_train.copy()\n",
        "t['e_desligado'] = y_train\n",
        "\n",
        "get_balance(t)"
      ],
      "metadata": {
        "id": "MtwIpQIcQ_ok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = X_test.copy()\n",
        "t['e_desligado'] = y_test\n",
        "\n",
        "get_balance(t)"
      ],
      "metadata": {
        "id": "t6DmZblBQ_mY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Amostragem com balanceamento"
      ],
      "metadata": {
        "id": "gmoZte-oREIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['e_desligado'] == 1].loc[:10]"
      ],
      "metadata": {
        "id": "pP3kmFnWQ_bi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df[df['e_desligado']==1])"
      ],
      "metadata": {
        "id": "BKeHuYvpS9IH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df[df['e_desligado']==1])*0.8"
      ],
      "metadata": {
        "id": "EMkvWUcNTD0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def get_features_labels_balanced(\n",
        "    df,\n",
        "    features,\n",
        "    p = 0.8,\n",
        "    target_label = 'e_desligado',\n",
        "   adjust_columns = False\n",
        "):\n",
        "    t = df.copy()\n",
        "\n",
        "    # shuffling indexes\n",
        "    t = t.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "    if adjust_columns:\n",
        "        t.columns = list(map(\n",
        "            lambda x: x.replace('.0', '').replace('>', 'maior').replace('<','menor').replace('[','').replace(']','').replace('-','').replace(',','_').replace('+','mais'),\n",
        "                                   t.columns))\n",
        "        t.columns = list(map(filter_alphanum_str, t.columns))\n",
        "\n",
        "        features = list(map(\n",
        "            lambda x: x.replace('.0', '').replace('>', 'maior').replace('<','menor').replace('[','').replace(']','').replace('-','').replace(',','_').replace('+','mais'),\n",
        "                                   features))\n",
        "        features = list(map(filter_alphanum_str, features))\n",
        "\n",
        "    # train data qtd\n",
        "    N = len(t)\n",
        "    N_train = math.ceil(N * p)\n",
        "    N_test = N - N_train\n",
        "\n",
        "    # initial balancement\n",
        "    qtd_pos = len(t[t[target_label] == 1])\n",
        "    qtd_neg = len(t[t[target_label] == 0])\n",
        "    print('qtd_pos: {} ({:.3f}%), qtd_neg: {} ({:.3f}%)'.format(\n",
        "        qtd_pos, (qtd_pos*100/(qtd_pos+qtd_neg)),\n",
        "        qtd_neg, (qtd_neg*100/(qtd_pos+qtd_neg))\n",
        "    ))\n",
        "    # label proportion\n",
        "    N_train_pos = math.ceil(qtd_pos * p)\n",
        "    N_train_neg =  math.ceil(qtd_neg * p)\n",
        "    N_tot = N_train_pos + N_train_neg\n",
        "    print('N_train_pos: {} ({:.3f}%), N_train_neg: {} ({:.3f}%)'.format(\n",
        "        N_train_pos, (N_train_pos*100/N_tot),\n",
        "        N_train_neg, (N_train_neg*100/N_tot)\n",
        "    ))\n",
        "    # positive samples\n",
        "    pos_train_data_sample = t[t[target_label] == 1].reset_index(drop=True).loc[:N_train_pos]\n",
        "\n",
        "    X_train_pos = pos_train_data_sample[features]\n",
        "    y_train_pos = pos_train_data_sample[target_label].values\n",
        "\n",
        "    # negative samples\n",
        "    neg_train_data_sample = t[t[target_label] == 0].reset_index(drop=True).loc[:N_train_neg]\n",
        "\n",
        "    X_train_neg = neg_train_data_sample[features]\n",
        "    y_train_neg = neg_train_data_sample[target_label].values\n",
        "\n",
        "\n",
        "    # Training data\n",
        "    X_train = pd.concat([X_train_pos, X_train_neg],\n",
        "                       axis = 0)\n",
        "    y_train = list(y_train_pos) + list(y_train_neg)\n",
        "\n",
        "\n",
        "    # test data\n",
        "    test_data_sample = t[\n",
        "        (~t.index.isin(pos_train_data_sample.index)) &\n",
        "        (~t.index.isin(neg_train_data_sample.index))\n",
        "    ]\n",
        "    X_test = test_data_sample[features]\n",
        "    y_test = test_data_sample[target_label].values\n",
        "\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "\n",
        "X_train, y_train, X_test, y_test = get_features_labels_balanced(\n",
        "    df,\n",
        "    features,\n",
        "    p = 0.8,\n",
        "    target_label = 'e_desligado',\n",
        "   adjust_columns = False\n",
        ")"
      ],
      "metadata": {
        "id": "zX3QYSdYS9ZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = X_train.copy()\n",
        "t['e_desligado'] = y_train\n",
        "\n",
        "get_balance(t)"
      ],
      "metadata": {
        "id": "cqWaeD15VJYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = X_test.copy()\n",
        "t['e_desligado'] = y_test\n",
        "\n",
        "get_balance(t)"
      ],
      "metadata": {
        "id": "meORp9JmVOId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preenchimento de Base"
      ],
      "metadata": {
        "id": "tGVGosgKVQsx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import missingno as msno"
      ],
      "metadata": {
        "id": "mQu5boShVQ7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(\n",
        "list(df0.columns)\n",
        ")"
      ],
      "metadata": {
        "id": "sux5ffSoVUrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title(\"Preenchimento das variÃ¡veis\",\n",
        "         fontsize = 20)\n",
        "plt.xlabel(\"% preenchimento\",\n",
        "          fontsize = 18)\n",
        "msno.bar(df0[list(df0.columns)[:51]])\n",
        "plt.figure(figsize=(5,8))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B--03oBoVUpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_missinng = pd.DataFrame({\n",
        "    'col': list(df0.columns),\n",
        "    'qtd_faltantes': list(map(lambda col: df0[col].isna().sum(),\n",
        "                             df0.columns\n",
        "                             )),\n",
        "    'pct_faltantes': list(map(lambda col: df0[col].isna().sum()*100/len(df0),\n",
        "                             df0.columns\n",
        "                             )),\n",
        "\n",
        "})\n",
        "df_missinng[df_missinng['pct_faltantes']>90].sort_values(by=['pct_faltantes'],\n",
        "                                                        ascending = False).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "p6VyFrWCVUnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title(\"Preenchimento das variÃ¡veis\",\n",
        "         fontsize = 20)\n",
        "plt.xlabel(\"% preenchimento\",\n",
        "          fontsize = 18)\n",
        "msno.bar(df0[list(df0.columns)[51:]])\n",
        "plt.figure(figsize=(5,8))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wTC-WfQUVUi-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}